{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jhara_mac/Desktop/plato/env/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seq2seq\n",
    "from seq2seq import *\n",
    "\n",
    "import re\n",
    "\n",
    "datadir = 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_file(filename='geobase.txt'):\n",
    "    kb = {}\n",
    "    with open(datadir+filename, 'r') as f:\n",
    "        for line in f:\n",
    "            if line.startswith('state'):\n",
    "                m = re.match('state\\((.*)\\).\\n', line.replace(\"'\", ''))\n",
    "                data = m.group(1).split(',')\n",
    "                \n",
    "                if 'state' not in kb:\n",
    "                    kb['state'] = []\n",
    "                \n",
    "                relations = ['abbreviation', 'capital', 'population', 'area', \\\n",
    "                             'state_number', 'city', 'city', 'city', 'city']\n",
    "                \n",
    "                for rel, subj in zip(relations, data[1:]):\n",
    "                    kb['state'].append((rel, subj, data[0]))\n",
    "\n",
    "            elif line.startswith('city'):\n",
    "                pass\n",
    "            elif line.startswith('river'):\n",
    "                pass\n",
    "            elif line.startswith('border'):\n",
    "                pass\n",
    "            elif line.startswith('highlow'):\n",
    "                pass\n",
    "            elif line.startswith('mountain'):\n",
    "                pass\n",
    "            elif line.startswith('road'):\n",
    "                pass\n",
    "            elif line.startswith('lake'):\n",
    "                pass\n",
    "            else:\n",
    "                pass\n",
    "    return kb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "kb = parse_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence(rel, subj, obj):\n",
    "    return '%s is %s of %s' % (subj, rel, obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fol(rel, subj, obj):\n",
    "    return '%s ( %s, %s )' % (rel, subj, obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['al is abbreviation of alabama', 'montgomery is capital of alabama', '3894.0e+3 is population of alabama', '51.7e+3 is area of alabama', '22 is state_number of alabama', 'birmingham is city of alabama', 'mobile is city of alabama', 'montgomery is city of alabama', 'huntsville is city of alabama', 'ak is abbreviation of alaska']\n",
      "['abbreviation ( al, alabama )', 'capital ( montgomery, alabama )', 'population ( 3894.0e+3, alabama )', 'area ( 51.7e+3, alabama )', 'state_number ( 22, alabama )', 'city ( birmingham, alabama )', 'city ( mobile, alabama )', 'city ( montgomery, alabama )', 'city ( huntsville, alabama )', 'abbreviation ( ak, alaska )']\n"
     ]
    }
   ],
   "source": [
    "src = []\n",
    "tar = []\n",
    "for tup in kb['state']:\n",
    "    src.append(generate_sentence(*tup))\n",
    "    tar.append(generate_fol(*tup))\n",
    "print src[:10]\n",
    "print tar[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(src)\n",
    "src_inputs = tokenizer.texts_to_sequences(src)\n",
    "src_inputs = pad_sequences(src_inputs,\n",
    "                           maxlen=max(len(seq) for seq in src_inputs))\n",
    "src_m, src_n = src_inputs.shape\n",
    "src_inputs = src_inputs.reshape((src_m, src_n, 1))\n",
    "\n",
    "tokenizer = Tokenizer(filters='!\"#$%&*+,-./:;<=>?@[\\]^_`{|}~')\n",
    "tokenizer.fit_on_texts(tar)\n",
    "tar_inputs = tokenizer.texts_to_sequences(tar)\n",
    "tar_inputs = pad_sequences(tar_inputs,\n",
    "                           maxlen=max(len(seq) for seq in tar_inputs))\n",
    "tar_m, tar_n = tar_inputs.shape\n",
    "tar_inputs = tar_inputs.reshape((tar_m, tar_n, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_seq2seq(src_inputs, tar_inputs, hidden_dim=100):\n",
    "    _, input_length, input_dim = src_inputs.shape\n",
    "    _, output_length, output_dim = tar_inputs.shape\n",
    "    \n",
    "    models = []\n",
    "    \n",
    "    # SIMPLE SEQ2SEQ\n",
    "    \n",
    "    # epoch 100: 7873.7063\n",
    "    # models += [SimpleSeq2Seq(output_dim=output_dim, hidden_dim=hidden_dim, output_length=output_length, input_shape=(input_length, input_dim))]\n",
    "    \n",
    "    # models += [SimpleSeq2Seq(output_dim=output_dim, hidden_dim=hidden_dim, output_length=output_length, input_shape=(input_length, input_dim), depth=2)]\n",
    "    # models += [SimpleSeq2Seq(output_dim=output_dim, hidden_dim=hidden_dim, output_length=output_length, input_shape=(input_length, input_dim), depth=4)]\n",
    "    \n",
    "    # epoch 100: 12396.6243\n",
    "    # models += [SimpleSeq2Seq(output_dim=output_dim, hidden_dim=hidden_dim, output_length=output_length, input_shape=(input_length, input_dim), depth=8)]\n",
    "\n",
    "    # SEQ2SEQ\n",
    " \n",
    "    models += [Seq2Seq(output_dim=output_dim, hidden_dim=hidden_dim, output_length=output_length, input_shape=(input_length, input_dim))]\n",
    "    models += [Seq2Seq(output_dim=output_dim, hidden_dim=hidden_dim, output_length=output_length, input_shape=(input_length, input_dim), peek=True)]\n",
    "    models += [Seq2Seq(output_dim=output_dim, hidden_dim=hidden_dim, output_length=output_length, input_shape=(input_length, input_dim), depth=4)]\n",
    "    # explodes\n",
    "    models += [Seq2Seq(output_dim=output_dim, hidden_dim=hidden_dim, output_length=output_length, input_shape=(input_length, input_dim), peek=True, depth=4)]\n",
    "    \n",
    "    # Attention\n",
    "    \n",
    "    models += [AttentionSeq2Seq(output_dim=output_dim, hidden_dim=hidden_dim, output_length=output_length, input_shape=(input_length, input_dim))]\n",
    "    #models += [AttentionSeq2Seq(output_dim=output_dim, hidden_dim=100, output_length=output_length, input_shape=(input_length, input_dim), depth=2)]\n",
    "    #models += [AttentionSeq2Seq(output_dim=output_dim, hidden_dim=200, output_length=output_length, input_shape=(input_length, input_dim), depth=2)]\n",
    "    #models += [AttentionSeq2Seq(output_dim=output_dim, hidden_dim=300, output_length=output_length, input_shape=(input_length, input_dim), depth=4)]\n",
    "    \n",
    "    histories = []\n",
    "    for model in models:\n",
    "        # model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['accuracy'])\n",
    "        model.compile(loss='mse', optimizer='rmsprop', metrics=['accuracy'])\n",
    "        history = model.fit(src_inputs, tar_inputs, nb_epoch=100)\n",
    "        histories.append(history)\n",
    "    return histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jhara_mac/Desktop/plato/env/lib/python2.7/site-packages/ipykernel_launcher.py:36: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "459/459 [==============================] - 17s 38ms/step - loss: 37.1995 - acc: 0.3387\n",
      "Epoch 2/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.8491 - acc: 0.3527\n",
      "Epoch 3/100\n",
      "459/459 [==============================] - 0s 989us/step - loss: 36.7250 - acc: 0.3309\n",
      "Epoch 4/100\n",
      "459/459 [==============================] - 1s 1ms/step - loss: 36.7095 - acc: 0.3801\n",
      "Epoch 5/100\n",
      "459/459 [==============================] - 1s 1ms/step - loss: 36.6824 - acc: 0.4231\n",
      "Epoch 6/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.6666 - acc: 0.4236\n",
      "Epoch 7/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.6579 - acc: 0.4471\n",
      "Epoch 8/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.6546 - acc: 0.4507\n",
      "Epoch 9/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.6535 - acc: 0.4483\n",
      "Epoch 10/100\n",
      "459/459 [==============================] - 1s 1ms/step - loss: 36.6503 - acc: 0.4507\n",
      "Epoch 11/100\n",
      "459/459 [==============================] - 0s 976us/step - loss: 36.6423 - acc: 0.4534\n",
      "Epoch 12/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.6288 - acc: 0.4578\n",
      "Epoch 13/100\n",
      "459/459 [==============================] - 0s 997us/step - loss: 36.6189 - acc: 0.4570\n",
      "Epoch 14/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.6103 - acc: 0.4585\n",
      "Epoch 15/100\n",
      "459/459 [==============================] - 0s 995us/step - loss: 36.6064 - acc: 0.4590\n",
      "Epoch 16/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.6242 - acc: 0.4524\n",
      "Epoch 17/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.6210 - acc: 0.4580\n",
      "Epoch 18/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.6194 - acc: 0.4544\n",
      "Epoch 19/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.6127 - acc: 0.4582\n",
      "Epoch 20/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.6121 - acc: 0.4573\n",
      "Epoch 21/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.6111 - acc: 0.4595\n",
      "Epoch 22/100\n",
      "459/459 [==============================] - 1s 1ms/step - loss: 36.6150 - acc: 0.4578\n",
      "Epoch 23/100\n",
      "459/459 [==============================] - 1s 1ms/step - loss: 36.6159 - acc: 0.4587\n",
      "Epoch 24/100\n",
      "459/459 [==============================] - 1s 1ms/step - loss: 36.6184 - acc: 0.4590\n",
      "Epoch 25/100\n",
      "459/459 [==============================] - 1s 1ms/step - loss: 36.6189 - acc: 0.4580\n",
      "Epoch 26/100\n",
      "459/459 [==============================] - 1s 1ms/step - loss: 36.6243 - acc: 0.4568\n",
      "Epoch 27/100\n",
      "459/459 [==============================] - 1s 1ms/step - loss: 36.6225 - acc: 0.4592\n",
      "Epoch 28/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.6210 - acc: 0.4553\n",
      "Epoch 29/100\n",
      "459/459 [==============================] - 1s 1ms/step - loss: 36.6116 - acc: 0.4587\n",
      "Epoch 30/100\n",
      "459/459 [==============================] - 1s 1ms/step - loss: 36.6124 - acc: 0.4587\n",
      "Epoch 31/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.6123 - acc: 0.4561\n",
      "Epoch 32/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.6040 - acc: 0.4602\n",
      "Epoch 33/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.6070 - acc: 0.4597\n",
      "Epoch 34/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.6016 - acc: 0.4602\n",
      "Epoch 35/100\n",
      "459/459 [==============================] - 1s 1ms/step - loss: 36.6082 - acc: 0.4587\n",
      "Epoch 36/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.6098 - acc: 0.4602\n",
      "Epoch 37/100\n",
      "459/459 [==============================] - 1s 1ms/step - loss: 36.6071 - acc: 0.4595\n",
      "Epoch 38/100\n",
      "459/459 [==============================] - 1s 1ms/step - loss: 36.6048 - acc: 0.4602\n",
      "Epoch 39/100\n",
      "459/459 [==============================] - 1s 1ms/step - loss: 36.6023 - acc: 0.4602\n",
      "Epoch 40/100\n",
      "459/459 [==============================] - 1s 1ms/step - loss: 36.6019 - acc: 0.4602\n",
      "Epoch 41/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.5996 - acc: 0.4602\n",
      "Epoch 42/100\n",
      "459/459 [==============================] - 1s 1ms/step - loss: 36.5968 - acc: 0.4599\n",
      "Epoch 43/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.5981 - acc: 0.4602\n",
      "Epoch 44/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.5952 - acc: 0.4602\n",
      "Epoch 45/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.5943 - acc: 0.4602\n",
      "Epoch 46/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.5931 - acc: 0.4602\n",
      "Epoch 47/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.5968 - acc: 0.4602: 0s - loss: 35.7294 - acc: \n",
      "Epoch 48/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.5952 - acc: 0.4602\n",
      "Epoch 49/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.5965 - acc: 0.4602\n",
      "Epoch 50/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.5937 - acc: 0.4602\n",
      "Epoch 51/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.5946 - acc: 0.4602\n",
      "Epoch 52/100\n",
      "459/459 [==============================] - 1s 1ms/step - loss: 36.5949 - acc: 0.4602\n",
      "Epoch 53/100\n",
      "459/459 [==============================] - 1s 1ms/step - loss: 36.5929 - acc: 0.4602\n",
      "Epoch 54/100\n",
      "459/459 [==============================] - 1s 1ms/step - loss: 36.5933 - acc: 0.4602\n",
      "Epoch 55/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.5923 - acc: 0.4602\n",
      "Epoch 56/100\n",
      "459/459 [==============================] - 1s 1ms/step - loss: 36.5936 - acc: 0.4602\n",
      "Epoch 57/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.5931 - acc: 0.4602\n",
      "Epoch 58/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.5913 - acc: 0.4602\n",
      "Epoch 59/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.5923 - acc: 0.4602\n",
      "Epoch 60/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.5922 - acc: 0.4602\n",
      "Epoch 61/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.5925 - acc: 0.4602\n",
      "Epoch 62/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.5934 - acc: 0.4602\n",
      "Epoch 63/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.5938 - acc: 0.4602\n",
      "Epoch 64/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.5917 - acc: 0.4602\n",
      "Epoch 65/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.5920 - acc: 0.4602\n",
      "Epoch 66/100\n",
      "459/459 [==============================] - 1s 1ms/step - loss: 36.5934 - acc: 0.4602\n",
      "Epoch 67/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.5917 - acc: 0.4602\n",
      "Epoch 68/100\n",
      "459/459 [==============================] - 1s 1ms/step - loss: 36.5927 - acc: 0.4602\n",
      "Epoch 69/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.5928 - acc: 0.4602\n",
      "Epoch 70/100\n",
      "459/459 [==============================] - 1s 1ms/step - loss: 36.5920 - acc: 0.4602\n",
      "Epoch 71/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.5951 - acc: 0.4602\n",
      "Epoch 72/100\n",
      "459/459 [==============================] - 1s 1ms/step - loss: 36.5925 - acc: 0.4602\n",
      "Epoch 73/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.5939 - acc: 0.4602\n",
      "Epoch 74/100\n",
      "459/459 [==============================] - 1s 1ms/step - loss: 36.5952 - acc: 0.4602\n",
      "Epoch 75/100\n",
      "459/459 [==============================] - 1s 1ms/step - loss: 36.5922 - acc: 0.4602\n",
      "Epoch 76/100\n",
      "459/459 [==============================] - 1s 1ms/step - loss: 36.5912 - acc: 0.4602\n",
      "Epoch 77/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.5913 - acc: 0.4602\n",
      "Epoch 78/100\n",
      "459/459 [==============================] - 1s 1ms/step - loss: 36.5919 - acc: 0.4602\n",
      "Epoch 79/100\n",
      "459/459 [==============================] - 1s 1ms/step - loss: 36.5928 - acc: 0.4602\n",
      "Epoch 80/100\n",
      "459/459 [==============================] - 1s 1ms/step - loss: 36.5941 - acc: 0.4602\n",
      "Epoch 81/100\n",
      "459/459 [==============================] - 1s 1ms/step - loss: 36.5910 - acc: 0.4602\n",
      "Epoch 82/100\n",
      "459/459 [==============================] - 1s 1ms/step - loss: 36.5926 - acc: 0.4602\n",
      "Epoch 83/100\n",
      "459/459 [==============================] - 1s 1ms/step - loss: 36.5931 - acc: 0.4602\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "459/459 [==============================] - 1s 1ms/step - loss: 36.5926 - acc: 0.4602\n",
      "Epoch 85/100\n",
      "459/459 [==============================] - 1s 1ms/step - loss: 36.5911 - acc: 0.4602\n",
      "Epoch 86/100\n",
      "459/459 [==============================] - 1s 1ms/step - loss: 36.5935 - acc: 0.4602\n",
      "Epoch 87/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.5925 - acc: 0.4602\n",
      "Epoch 88/100\n",
      "459/459 [==============================] - 1s 1ms/step - loss: 36.5936 - acc: 0.4602\n",
      "Epoch 89/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.5946 - acc: 0.4602\n",
      "Epoch 90/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.5923 - acc: 0.4602\n",
      "Epoch 91/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.5933 - acc: 0.4602\n",
      "Epoch 92/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.5922 - acc: 0.4602\n",
      "Epoch 93/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.5914 - acc: 0.4602\n",
      "Epoch 94/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.5919 - acc: 0.4602\n",
      "Epoch 95/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.5944 - acc: 0.4602\n",
      "Epoch 96/100\n",
      "459/459 [==============================] - 1s 1ms/step - loss: 36.5954 - acc: 0.4602\n",
      "Epoch 97/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.5914 - acc: 0.4602\n",
      "Epoch 98/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.5907 - acc: 0.4602\n",
      "Epoch 99/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.5919 - acc: 0.4602\n",
      "Epoch 100/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.5912 - acc: 0.4602\n",
      "Epoch 1/100\n",
      "459/459 [==============================] - 16s 34ms/step - loss: 36.8854 - acc: 0.3159\n",
      "Epoch 2/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.7232 - acc: 0.3725\n",
      "Epoch 3/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.6914 - acc: 0.4122\n",
      "Epoch 4/100\n",
      "459/459 [==============================] - 1s 1ms/step - loss: 36.6751 - acc: 0.4236\n",
      "Epoch 5/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.6566 - acc: 0.4401\n",
      "Epoch 6/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.6496 - acc: 0.4478\n",
      "Epoch 7/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.6430 - acc: 0.4558\n",
      "Epoch 8/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.6313 - acc: 0.4568\n",
      "Epoch 9/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.6334 - acc: 0.4517\n",
      "Epoch 10/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.6248 - acc: 0.4553\n",
      "Epoch 11/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.6133 - acc: 0.4578\n",
      "Epoch 12/100\n",
      "459/459 [==============================] - 1s 1ms/step - loss: 36.6187 - acc: 0.4582\n",
      "Epoch 13/100\n",
      "459/459 [==============================] - 1s 1ms/step - loss: 36.6186 - acc: 0.4553\n",
      "Epoch 14/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.6107 - acc: 0.4578\n",
      "Epoch 15/100\n",
      "459/459 [==============================] - 1s 1ms/step - loss: 36.6040 - acc: 0.4585\n",
      "Epoch 16/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.6070 - acc: 0.4585\n",
      "Epoch 17/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.6046 - acc: 0.4582\n",
      "Epoch 18/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.6029 - acc: 0.4580\n",
      "Epoch 19/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.6012 - acc: 0.4585\n",
      "Epoch 20/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.5981 - acc: 0.4582\n",
      "Epoch 21/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.5995 - acc: 0.4595\n",
      "Epoch 22/100\n",
      "459/459 [==============================] - 1s 1ms/step - loss: 36.5968 - acc: 0.4597\n",
      "Epoch 23/100\n",
      "459/459 [==============================] - 1s 1ms/step - loss: 36.5965 - acc: 0.4595\n",
      "Epoch 24/100\n",
      "459/459 [==============================] - 1s 1ms/step - loss: 36.5966 - acc: 0.4597\n",
      "Epoch 25/100\n",
      "459/459 [==============================] - 1s 1ms/step - loss: 36.5965 - acc: 0.4597\n",
      "Epoch 26/100\n",
      "459/459 [==============================] - 1s 1ms/step - loss: 36.5974 - acc: 0.4602\n",
      "Epoch 27/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.5949 - acc: 0.4602\n",
      "Epoch 28/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.5941 - acc: 0.4597\n",
      "Epoch 29/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.5942 - acc: 0.4602\n",
      "Epoch 30/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.5953 - acc: 0.4602\n",
      "Epoch 31/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.5979 - acc: 0.4599\n",
      "Epoch 32/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.5966 - acc: 0.4599\n",
      "Epoch 33/100\n",
      "459/459 [==============================] - 1s 1ms/step - loss: 36.5956 - acc: 0.4602\n",
      "Epoch 34/100\n",
      "459/459 [==============================] - 1s 1ms/step - loss: 36.5941 - acc: 0.4602\n",
      "Epoch 35/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.5929 - acc: 0.4602\n",
      "Epoch 36/100\n",
      "459/459 [==============================] - 1s 1ms/step - loss: 36.5927 - acc: 0.4602\n",
      "Epoch 37/100\n",
      "459/459 [==============================] - 1s 1ms/step - loss: 36.5923 - acc: 0.4602\n",
      "Epoch 38/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.5950 - acc: 0.4602\n",
      "Epoch 39/100\n",
      "459/459 [==============================] - 1s 1ms/step - loss: 36.5928 - acc: 0.4602\n",
      "Epoch 40/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.5913 - acc: 0.4602\n",
      "Epoch 41/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.5916 - acc: 0.4602\n",
      "Epoch 42/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.5921 - acc: 0.4602\n",
      "Epoch 43/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.5928 - acc: 0.4602\n",
      "Epoch 44/100\n",
      "459/459 [==============================] - 1s 1ms/step - loss: 36.5934 - acc: 0.4602\n",
      "Epoch 45/100\n",
      "459/459 [==============================] - 1s 1ms/step - loss: 36.5931 - acc: 0.4602\n",
      "Epoch 46/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.5923 - acc: 0.4602\n",
      "Epoch 47/100\n",
      "459/459 [==============================] - 1s 1ms/step - loss: 36.5925 - acc: 0.4602\n",
      "Epoch 48/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.5924 - acc: 0.4602\n",
      "Epoch 49/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.5915 - acc: 0.4602\n",
      "Epoch 50/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.5917 - acc: 0.4602\n",
      "Epoch 51/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.5914 - acc: 0.4602\n",
      "Epoch 52/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.5908 - acc: 0.4602\n",
      "Epoch 53/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.5916 - acc: 0.4602\n",
      "Epoch 54/100\n",
      "459/459 [==============================] - 1s 1ms/step - loss: 36.5905 - acc: 0.4602\n",
      "Epoch 55/100\n",
      "459/459 [==============================] - 1s 1ms/step - loss: 36.5917 - acc: 0.4602\n",
      "Epoch 56/100\n",
      "459/459 [==============================] - 1s 1ms/step - loss: 36.5915 - acc: 0.4602\n",
      "Epoch 57/100\n",
      "459/459 [==============================] - 1s 1ms/step - loss: 36.5910 - acc: 0.4602\n",
      "Epoch 58/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.5916 - acc: 0.4602\n",
      "Epoch 59/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.5918 - acc: 0.4602\n",
      "Epoch 60/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.5916 - acc: 0.4602\n",
      "Epoch 61/100\n",
      "459/459 [==============================] - 1s 1ms/step - loss: 36.5904 - acc: 0.4602\n",
      "Epoch 62/100\n",
      "459/459 [==============================] - 1s 1ms/step - loss: 36.5897 - acc: 0.4602\n",
      "Epoch 63/100\n",
      "459/459 [==============================] - 1s 1ms/step - loss: 36.5909 - acc: 0.4602\n",
      "Epoch 64/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.5914 - acc: 0.4602\n",
      "Epoch 65/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.5915 - acc: 0.4602\n",
      "Epoch 66/100\n",
      "459/459 [==============================] - 1s 1ms/step - loss: 36.5911 - acc: 0.4602\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "459/459 [==============================] - 0s 1ms/step - loss: 36.5917 - acc: 0.4602\n",
      "Epoch 68/100\n",
      "459/459 [==============================] - 0s 992us/step - loss: 36.5916 - acc: 0.4602\n",
      "Epoch 69/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.5926 - acc: 0.4602\n",
      "Epoch 70/100\n",
      "459/459 [==============================] - 0s 997us/step - loss: 36.5914 - acc: 0.4602\n",
      "Epoch 71/100\n",
      "459/459 [==============================] - 0s 978us/step - loss: 36.5899 - acc: 0.4602\n",
      "Epoch 72/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.5897 - acc: 0.4602\n",
      "Epoch 73/100\n",
      "459/459 [==============================] - 0s 995us/step - loss: 36.5898 - acc: 0.4602\n",
      "Epoch 74/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.5907 - acc: 0.4602\n",
      "Epoch 75/100\n",
      "459/459 [==============================] - 1s 1ms/step - loss: 36.5907 - acc: 0.4602\n",
      "Epoch 76/100\n",
      "459/459 [==============================] - 0s 986us/step - loss: 36.5925 - acc: 0.4602\n",
      "Epoch 77/100\n",
      "459/459 [==============================] - 1s 1ms/step - loss: 36.5898 - acc: 0.4602\n",
      "Epoch 78/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.5906 - acc: 0.4602\n",
      "Epoch 79/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.5910 - acc: 0.4602\n",
      "Epoch 80/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.5906 - acc: 0.4602\n",
      "Epoch 81/100\n",
      "459/459 [==============================] - 1s 1ms/step - loss: 36.5911 - acc: 0.4602\n",
      "Epoch 82/100\n",
      "459/459 [==============================] - 1s 1ms/step - loss: 36.5932 - acc: 0.4602\n",
      "Epoch 83/100\n",
      "459/459 [==============================] - 1s 1ms/step - loss: 36.5909 - acc: 0.4602\n",
      "Epoch 84/100\n",
      "459/459 [==============================] - 0s 987us/step - loss: 36.5904 - acc: 0.4602\n",
      "Epoch 85/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.5903 - acc: 0.4602\n",
      "Epoch 86/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.5917 - acc: 0.4602\n",
      "Epoch 87/100\n",
      "459/459 [==============================] - 1s 2ms/step - loss: 36.5910 - acc: 0.4602\n",
      "Epoch 88/100\n",
      "459/459 [==============================] - 1s 1ms/step - loss: 36.5924 - acc: 0.4602\n",
      "Epoch 89/100\n",
      "459/459 [==============================] - 1s 1ms/step - loss: 36.5924 - acc: 0.4602\n",
      "Epoch 90/100\n",
      "459/459 [==============================] - 1s 1ms/step - loss: 36.5909 - acc: 0.4602\n",
      "Epoch 91/100\n",
      "459/459 [==============================] - 1s 1ms/step - loss: 36.5898 - acc: 0.4602\n",
      "Epoch 92/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.5901 - acc: 0.4602\n",
      "Epoch 93/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.5907 - acc: 0.4602\n",
      "Epoch 94/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.5914 - acc: 0.4602\n",
      "Epoch 95/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.5896 - acc: 0.4602\n",
      "Epoch 96/100\n",
      "459/459 [==============================] - 1s 1ms/step - loss: 36.5898 - acc: 0.4602\n",
      "Epoch 97/100\n",
      "459/459 [==============================] - 0s 1ms/step - loss: 36.5899 - acc: 0.4602\n",
      "Epoch 98/100\n",
      "459/459 [==============================] - 1s 1ms/step - loss: 36.5905 - acc: 0.4602\n",
      "Epoch 99/100\n",
      "459/459 [==============================] - 0s 996us/step - loss: 36.5902 - acc: 0.4602\n",
      "Epoch 100/100\n",
      "459/459 [==============================] - 1s 1ms/step - loss: 36.5893 - acc: 0.4602: 0s - loss: 36.6526 - acc\n",
      "Epoch 1/100\n",
      "459/459 [==============================] - 19s 41ms/step - loss: 37.2126 - acc: 0.3491\n",
      "Epoch 2/100\n",
      "459/459 [==============================] - 1s 3ms/step - loss: 36.9496 - acc: 0.3571\n",
      "Epoch 3/100\n",
      "459/459 [==============================] - 1s 3ms/step - loss: 36.7628 - acc: 0.3246\n",
      "Epoch 4/100\n",
      "459/459 [==============================] - 1s 3ms/step - loss: 36.7381 - acc: 0.3604\n",
      "Epoch 5/100\n",
      "459/459 [==============================] - 1s 3ms/step - loss: 36.7195 - acc: 0.3883\n",
      "Epoch 6/100\n",
      "459/459 [==============================] - 1s 3ms/step - loss: 36.6912 - acc: 0.4110\n",
      "Epoch 7/100\n",
      "459/459 [==============================] - 2s 3ms/step - loss: 36.6833 - acc: 0.4161\n",
      "Epoch 8/100\n",
      "459/459 [==============================] - 2s 3ms/step - loss: 36.6695 - acc: 0.4420\n",
      "Epoch 9/100\n",
      "459/459 [==============================] - 1s 3ms/step - loss: 36.6560 - acc: 0.4464\n",
      "Epoch 10/100\n",
      "459/459 [==============================] - 1s 3ms/step - loss: 36.6503 - acc: 0.4476\n",
      "Epoch 11/100\n",
      "459/459 [==============================] - 1s 3ms/step - loss: 36.6457 - acc: 0.4476\n",
      "Epoch 12/100\n",
      "459/459 [==============================] - 1s 3ms/step - loss: 36.6396 - acc: 0.4556\n",
      "Epoch 13/100\n",
      "459/459 [==============================] - 1s 3ms/step - loss: 36.6313 - acc: 0.4582\n",
      "Epoch 14/100\n",
      "459/459 [==============================] - 1s 3ms/step - loss: 36.6247 - acc: 0.4582\n",
      "Epoch 15/100\n",
      "459/459 [==============================] - 2s 4ms/step - loss: 36.6179 - acc: 0.4587\n",
      "Epoch 16/100\n",
      "459/459 [==============================] - 2s 3ms/step - loss: 36.6129 - acc: 0.4592\n",
      "Epoch 17/100\n",
      "459/459 [==============================] - 1s 3ms/step - loss: 36.6075 - acc: 0.4595\n",
      "Epoch 18/100\n",
      "459/459 [==============================] - 1s 3ms/step - loss: 36.6026 - acc: 0.4595\n",
      "Epoch 19/100\n",
      "459/459 [==============================] - 1s 3ms/step - loss: 36.6033 - acc: 0.4599\n",
      "Epoch 20/100\n",
      "459/459 [==============================] - 1s 3ms/step - loss: 36.6006 - acc: 0.4599\n",
      "Epoch 21/100\n",
      "459/459 [==============================] - 1s 3ms/step - loss: 36.5962 - acc: 0.4595\n",
      "Epoch 22/100\n",
      "459/459 [==============================] - 1s 3ms/step - loss: 36.5936 - acc: 0.4597\n",
      "Epoch 23/100\n",
      "459/459 [==============================] - 1s 3ms/step - loss: 36.5919 - acc: 0.4597\n",
      "Epoch 24/100\n",
      "459/459 [==============================] - 1s 3ms/step - loss: 36.5910 - acc: 0.4599\n",
      "Epoch 25/100\n",
      "459/459 [==============================] - 1s 3ms/step - loss: 36.5978 - acc: 0.4570\n",
      "Epoch 26/100\n",
      "459/459 [==============================] - 1s 3ms/step - loss: 36.5941 - acc: 0.4592\n",
      "Epoch 27/100\n",
      "459/459 [==============================] - 1s 3ms/step - loss: 36.5984 - acc: 0.4551\n",
      "Epoch 28/100\n",
      "459/459 [==============================] - 1s 3ms/step - loss: 36.6385 - acc: 0.4345\n",
      "Epoch 29/100\n",
      "459/459 [==============================] - 1s 3ms/step - loss: 36.6437 - acc: 0.4360\n",
      "Epoch 30/100\n",
      "459/459 [==============================] - 1s 3ms/step - loss: 36.6738 - acc: 0.4055\n",
      "Epoch 31/100\n",
      "459/459 [==============================] - 1s 3ms/step - loss: 36.6668 - acc: 0.4219\n",
      "Epoch 32/100\n",
      "459/459 [==============================] - 1s 3ms/step - loss: 36.6797 - acc: 0.4079\n",
      "Epoch 33/100\n",
      "459/459 [==============================] - 1s 3ms/step - loss: 36.6693 - acc: 0.4198: 1s - l\n",
      "Epoch 34/100\n",
      "459/459 [==============================] - 1s 3ms/step - loss: 36.6723 - acc: 0.4236\n",
      "Epoch 35/100\n",
      "459/459 [==============================] - 1s 3ms/step - loss: 36.6819 - acc: 0.4001\n",
      "Epoch 36/100\n",
      "459/459 [==============================] - 2s 4ms/step - loss: 36.6942 - acc: 0.4147\n",
      "Epoch 37/100\n",
      "459/459 [==============================] - 2s 3ms/step - loss: 36.6751 - acc: 0.4205\n",
      "Epoch 38/100\n",
      "459/459 [==============================] - 1s 3ms/step - loss: 36.6788 - acc: 0.4096\n",
      "Epoch 39/100\n",
      "459/459 [==============================] - 1s 3ms/step - loss: 36.6901 - acc: 0.3939\n",
      "Epoch 40/100\n",
      "459/459 [==============================] - 1s 3ms/step - loss: 36.7032 - acc: 0.3798\n",
      "Epoch 41/100\n",
      "459/459 [==============================] - 1s 3ms/step - loss: 36.6948 - acc: 0.3883\n",
      "Epoch 42/100\n",
      "459/459 [==============================] - 1s 3ms/step - loss: 36.6968 - acc: 0.3856\n",
      "Epoch 43/100\n",
      "459/459 [==============================] - 2s 4ms/step - loss: 36.6981 - acc: 0.3854\n",
      "Epoch 44/100\n",
      "459/459 [==============================] - 2s 4ms/step - loss: 36.6865 - acc: 0.4127\n",
      "Epoch 45/100\n",
      "459/459 [==============================] - 2s 4ms/step - loss: 36.6899 - acc: 0.4023\n",
      "Epoch 46/100\n",
      "459/459 [==============================] - 2s 4ms/step - loss: 36.6901 - acc: 0.4045\n",
      "Epoch 47/100\n",
      "459/459 [==============================] - 2s 3ms/step - loss: 36.6884 - acc: 0.4113\n",
      "Epoch 48/100\n",
      "459/459 [==============================] - 2s 4ms/step - loss: 36.6999 - acc: 0.3939\n",
      "Epoch 49/100\n",
      "459/459 [==============================] - 1s 3ms/step - loss: 36.6897 - acc: 0.4086\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "459/459 [==============================] - 1s 3ms/step - loss: 36.6858 - acc: 0.4038\n",
      "Epoch 51/100\n",
      "459/459 [==============================] - 1s 3ms/step - loss: 36.6894 - acc: 0.3955\n",
      "Epoch 52/100\n",
      "459/459 [==============================] - 2s 3ms/step - loss: 36.6831 - acc: 0.3997\n",
      "Epoch 53/100\n",
      "459/459 [==============================] - 2s 4ms/step - loss: 36.6811 - acc: 0.4079\n",
      "Epoch 54/100\n",
      "459/459 [==============================] - 2s 3ms/step - loss: 36.6864 - acc: 0.4096\n",
      "Epoch 55/100\n",
      "459/459 [==============================] - 2s 4ms/step - loss: 36.6846 - acc: 0.4018\n",
      "Epoch 56/100\n",
      "459/459 [==============================] - 2s 3ms/step - loss: 36.6841 - acc: 0.3958\n",
      "Epoch 57/100\n",
      "459/459 [==============================] - 2s 4ms/step - loss: 36.6878 - acc: 0.3951\n",
      "Epoch 58/100\n",
      "459/459 [==============================] - 1s 3ms/step - loss: 36.6811 - acc: 0.3948\n",
      "Epoch 59/100\n",
      "459/459 [==============================] - 1s 3ms/step - loss: 36.6811 - acc: 0.3985\n",
      "Epoch 60/100\n",
      "459/459 [==============================] - 2s 3ms/step - loss: 36.6817 - acc: 0.3987\n",
      "Epoch 61/100\n",
      "459/459 [==============================] - 1s 3ms/step - loss: 36.6808 - acc: 0.3985\n",
      "Epoch 62/100\n",
      "459/459 [==============================] - 2s 3ms/step - loss: 36.6783 - acc: 0.4045\n",
      "Epoch 63/100\n",
      "459/459 [==============================] - 1s 3ms/step - loss: 36.6776 - acc: 0.4021\n",
      "Epoch 64/100\n",
      "459/459 [==============================] - 2s 3ms/step - loss: 36.6794 - acc: 0.4006\n",
      "Epoch 65/100\n",
      "459/459 [==============================] - 1s 3ms/step - loss: 36.6760 - acc: 0.4011\n",
      "Epoch 66/100\n",
      "459/459 [==============================] - 2s 3ms/step - loss: 36.6760 - acc: 0.4067: 0s - loss: 37.\n",
      "Epoch 67/100\n",
      "459/459 [==============================] - 1s 3ms/step - loss: 36.6769 - acc: 0.4079\n",
      "Epoch 68/100\n",
      "459/459 [==============================] - 1s 3ms/step - loss: 36.6806 - acc: 0.3992\n",
      "Epoch 69/100\n",
      "459/459 [==============================] - 1s 3ms/step - loss: nan - acc: 0.2220\n",
      "Epoch 70/100\n",
      "459/459 [==============================] - 1s 3ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 71/100\n",
      "459/459 [==============================] - 1s 3ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 72/100\n",
      "459/459 [==============================] - 2s 3ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 73/100\n",
      "459/459 [==============================] - 1s 3ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 74/100\n",
      "459/459 [==============================] - 1s 3ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 75/100\n",
      "459/459 [==============================] - 1s 3ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 76/100\n",
      "459/459 [==============================] - 1s 3ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 77/100\n",
      "459/459 [==============================] - 1s 3ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 78/100\n",
      "459/459 [==============================] - 1s 3ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 79/100\n",
      "459/459 [==============================] - 2s 3ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 80/100\n",
      "459/459 [==============================] - 2s 4ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 81/100\n",
      "459/459 [==============================] - 2s 4ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 82/100\n",
      "459/459 [==============================] - 2s 4ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 83/100\n",
      "459/459 [==============================] - 2s 4ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 84/100\n",
      "459/459 [==============================] - 2s 4ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 85/100\n",
      "459/459 [==============================] - 1s 3ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 86/100\n",
      "459/459 [==============================] - 2s 4ms/step - loss: nan - acc: 0.0000e+00\n",
      "Epoch 87/100\n",
      "128/459 [=======>......................] - ETA: 1s - loss: nan - acc: 0.0000e+00"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-c05b017e0a5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistories\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_seq2seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-33-3509cf2ec7f9>\u001b[0m in \u001b[0;36mtest_seq2seq\u001b[0;34m(src_inputs, tar_inputs, hidden_dim)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean_absolute_error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mhistories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhistories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jhara_mac/Desktop/plato/env/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/Users/jhara_mac/Desktop/plato/env/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1234\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1236\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1237\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jhara_mac/Desktop/plato/env/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2482\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jhara_mac/Desktop/plato/env/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jhara_mac/Desktop/plato/env/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jhara_mac/Desktop/plato/env/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jhara_mac/Desktop/plato/env/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jhara_mac/Desktop/plato/env/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jhara_mac/Desktop/plato/env/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "histories = test_seq2seq(src_inputs, tar_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    loss_list = [s for s in history.history.keys() if 'loss' in s and 'val' not in s]\n",
    "    val_loss_list = [s for s in history.history.keys() if 'loss' in s and 'val' in s]\n",
    "    acc_list = [s for s in history.history.keys() if 'acc' in s and 'val' not in s]\n",
    "    val_acc_list = [s for s in history.history.keys() if 'acc' in s and 'val' in s]\n",
    "    \n",
    "    if len(loss_list) == 0:\n",
    "        print('Loss is missing in history')\n",
    "        return \n",
    "    \n",
    "    ## As loss always exists\n",
    "    epochs = range(1,len(history.history[loss_list[0]]) + 1)\n",
    "    \n",
    "    ## Loss\n",
    "    plt.figure(1)\n",
    "    for l in loss_list:\n",
    "        plt.plot(epochs, history.history[l], 'b', label='Training loss (' + str(str(format(history.history[l][-1],'.5f'))+')'))\n",
    "    for l in val_loss_list:\n",
    "        plt.plot(epochs, history.history[l], 'g', label='Validation loss (' + str(str(format(history.history[l][-1],'.5f'))+')'))\n",
    "    \n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    ## Accuracy\n",
    "    plt.figure(2)\n",
    "    for l in acc_list:\n",
    "        plt.plot(epochs, history.history[l], 'b', label='Training accuracy (' + str(format(history.history[l][-1],'.5f'))+')')\n",
    "    for l in val_acc_list:    \n",
    "        plt.plot(epochs, history.history[l], 'g', label='Validation accuracy (' + str(format(history.history[l][-1],'.5f'))+')')\n",
    "\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTING THE SIMPLE SEQ2SEQ\n",
    "for history in histories:\n",
    "    plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEQ2SEQ\n",
    "for history in histories:\n",
    "    plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
